{"ast":null,"code":"import _asyncToGenerator from \"C:\\\\PythonProjects\\\\Fashion\\\\YOLOTFjf\\\\tfjs-yolov5-example\\\\node_modules\\\\@babel\\\\runtime/helpers/esm/asyncToGenerator\";\n\nfunction _regeneratorRuntime() { \"use strict\"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return exports; }; var exports = {}, Op = Object.prototype, hasOwn = Op.hasOwnProperty, $Symbol = \"function\" == typeof Symbol ? Symbol : {}, iteratorSymbol = $Symbol.iterator || \"@@iterator\", asyncIteratorSymbol = $Symbol.asyncIterator || \"@@asyncIterator\", toStringTagSymbol = $Symbol.toStringTag || \"@@toStringTag\"; function define(obj, key, value) { return Object.defineProperty(obj, key, { value: value, enumerable: !0, configurable: !0, writable: !0 }), obj[key]; } try { define({}, \"\"); } catch (err) { define = function define(obj, key, value) { return obj[key] = value; }; } function wrap(innerFn, outerFn, self, tryLocsList) { var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator, generator = Object.create(protoGenerator.prototype), context = new Context(tryLocsList || []); return generator._invoke = function (innerFn, self, context) { var state = \"suspendedStart\"; return function (method, arg) { if (\"executing\" === state) throw new Error(\"Generator is already running\"); if (\"completed\" === state) { if (\"throw\" === method) throw arg; return doneResult(); } for (context.method = method, context.arg = arg;;) { var delegate = context.delegate; if (delegate) { var delegateResult = maybeInvokeDelegate(delegate, context); if (delegateResult) { if (delegateResult === ContinueSentinel) continue; return delegateResult; } } if (\"next\" === context.method) context.sent = context._sent = context.arg;else if (\"throw\" === context.method) { if (\"suspendedStart\" === state) throw state = \"completed\", context.arg; context.dispatchException(context.arg); } else \"return\" === context.method && context.abrupt(\"return\", context.arg); state = \"executing\"; var record = tryCatch(innerFn, self, context); if (\"normal\" === record.type) { if (state = context.done ? \"completed\" : \"suspendedYield\", record.arg === ContinueSentinel) continue; return { value: record.arg, done: context.done }; } \"throw\" === record.type && (state = \"completed\", context.method = \"throw\", context.arg = record.arg); } }; }(innerFn, self, context), generator; } function tryCatch(fn, obj, arg) { try { return { type: \"normal\", arg: fn.call(obj, arg) }; } catch (err) { return { type: \"throw\", arg: err }; } } exports.wrap = wrap; var ContinueSentinel = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var IteratorPrototype = {}; define(IteratorPrototype, iteratorSymbol, function () { return this; }); var getProto = Object.getPrototypeOf, NativeIteratorPrototype = getProto && getProto(getProto(values([]))); NativeIteratorPrototype && NativeIteratorPrototype !== Op && hasOwn.call(NativeIteratorPrototype, iteratorSymbol) && (IteratorPrototype = NativeIteratorPrototype); var Gp = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(IteratorPrototype); function defineIteratorMethods(prototype) { [\"next\", \"throw\", \"return\"].forEach(function (method) { define(prototype, method, function (arg) { return this._invoke(method, arg); }); }); } function AsyncIterator(generator, PromiseImpl) { function invoke(method, arg, resolve, reject) { var record = tryCatch(generator[method], generator, arg); if (\"throw\" !== record.type) { var result = record.arg, value = result.value; return value && \"object\" == typeof value && hasOwn.call(value, \"__await\") ? PromiseImpl.resolve(value.__await).then(function (value) { invoke(\"next\", value, resolve, reject); }, function (err) { invoke(\"throw\", err, resolve, reject); }) : PromiseImpl.resolve(value).then(function (unwrapped) { result.value = unwrapped, resolve(result); }, function (error) { return invoke(\"throw\", error, resolve, reject); }); } reject(record.arg); } var previousPromise; this._invoke = function (method, arg) { function callInvokeWithMethodAndArg() { return new PromiseImpl(function (resolve, reject) { invoke(method, arg, resolve, reject); }); } return previousPromise = previousPromise ? previousPromise.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); }; } function maybeInvokeDelegate(delegate, context) { var method = delegate.iterator[context.method]; if (undefined === method) { if (context.delegate = null, \"throw\" === context.method) { if (delegate.iterator.return && (context.method = \"return\", context.arg = undefined, maybeInvokeDelegate(delegate, context), \"throw\" === context.method)) return ContinueSentinel; context.method = \"throw\", context.arg = new TypeError(\"The iterator does not provide a 'throw' method\"); } return ContinueSentinel; } var record = tryCatch(method, delegate.iterator, context.arg); if (\"throw\" === record.type) return context.method = \"throw\", context.arg = record.arg, context.delegate = null, ContinueSentinel; var info = record.arg; return info ? info.done ? (context[delegate.resultName] = info.value, context.next = delegate.nextLoc, \"return\" !== context.method && (context.method = \"next\", context.arg = undefined), context.delegate = null, ContinueSentinel) : info : (context.method = \"throw\", context.arg = new TypeError(\"iterator result is not an object\"), context.delegate = null, ContinueSentinel); } function pushTryEntry(locs) { var entry = { tryLoc: locs[0] }; 1 in locs && (entry.catchLoc = locs[1]), 2 in locs && (entry.finallyLoc = locs[2], entry.afterLoc = locs[3]), this.tryEntries.push(entry); } function resetTryEntry(entry) { var record = entry.completion || {}; record.type = \"normal\", delete record.arg, entry.completion = record; } function Context(tryLocsList) { this.tryEntries = [{ tryLoc: \"root\" }], tryLocsList.forEach(pushTryEntry, this), this.reset(!0); } function values(iterable) { if (iterable) { var iteratorMethod = iterable[iteratorSymbol]; if (iteratorMethod) return iteratorMethod.call(iterable); if (\"function\" == typeof iterable.next) return iterable; if (!isNaN(iterable.length)) { var i = -1, next = function next() { for (; ++i < iterable.length;) { if (hasOwn.call(iterable, i)) return next.value = iterable[i], next.done = !1, next; } return next.value = undefined, next.done = !0, next; }; return next.next = next; } } return { next: doneResult }; } function doneResult() { return { value: undefined, done: !0 }; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, define(Gp, \"constructor\", GeneratorFunctionPrototype), define(GeneratorFunctionPrototype, \"constructor\", GeneratorFunction), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, toStringTagSymbol, \"GeneratorFunction\"), exports.isGeneratorFunction = function (genFun) { var ctor = \"function\" == typeof genFun && genFun.constructor; return !!ctor && (ctor === GeneratorFunction || \"GeneratorFunction\" === (ctor.displayName || ctor.name)); }, exports.mark = function (genFun) { return Object.setPrototypeOf ? Object.setPrototypeOf(genFun, GeneratorFunctionPrototype) : (genFun.__proto__ = GeneratorFunctionPrototype, define(genFun, toStringTagSymbol, \"GeneratorFunction\")), genFun.prototype = Object.create(Gp), genFun; }, exports.awrap = function (arg) { return { __await: arg }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, asyncIteratorSymbol, function () { return this; }), exports.AsyncIterator = AsyncIterator, exports.async = function (innerFn, outerFn, self, tryLocsList, PromiseImpl) { void 0 === PromiseImpl && (PromiseImpl = Promise); var iter = new AsyncIterator(wrap(innerFn, outerFn, self, tryLocsList), PromiseImpl); return exports.isGeneratorFunction(outerFn) ? iter : iter.next().then(function (result) { return result.done ? result.value : iter.next(); }); }, defineIteratorMethods(Gp), define(Gp, toStringTagSymbol, \"Generator\"), define(Gp, iteratorSymbol, function () { return this; }), define(Gp, \"toString\", function () { return \"[object Generator]\"; }), exports.keys = function (object) { var keys = []; for (var key in object) { keys.push(key); } return keys.reverse(), function next() { for (; keys.length;) { var key = keys.pop(); if (key in object) return next.value = key, next.done = !1, next; } return next.done = !0, next; }; }, exports.values = values, Context.prototype = { constructor: Context, reset: function reset(skipTempReset) { if (this.prev = 0, this.next = 0, this.sent = this._sent = undefined, this.done = !1, this.delegate = null, this.method = \"next\", this.arg = undefined, this.tryEntries.forEach(resetTryEntry), !skipTempReset) for (var name in this) { \"t\" === name.charAt(0) && hasOwn.call(this, name) && !isNaN(+name.slice(1)) && (this[name] = undefined); } }, stop: function stop() { this.done = !0; var rootRecord = this.tryEntries[0].completion; if (\"throw\" === rootRecord.type) throw rootRecord.arg; return this.rval; }, dispatchException: function dispatchException(exception) { if (this.done) throw exception; var context = this; function handle(loc, caught) { return record.type = \"throw\", record.arg = exception, context.next = loc, caught && (context.method = \"next\", context.arg = undefined), !!caught; } for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i], record = entry.completion; if (\"root\" === entry.tryLoc) return handle(\"end\"); if (entry.tryLoc <= this.prev) { var hasCatch = hasOwn.call(entry, \"catchLoc\"), hasFinally = hasOwn.call(entry, \"finallyLoc\"); if (hasCatch && hasFinally) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } else if (hasCatch) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); } else { if (!hasFinally) throw new Error(\"try statement without catch or finally\"); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } } } }, abrupt: function abrupt(type, arg) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc <= this.prev && hasOwn.call(entry, \"finallyLoc\") && this.prev < entry.finallyLoc) { var finallyEntry = entry; break; } } finallyEntry && (\"break\" === type || \"continue\" === type) && finallyEntry.tryLoc <= arg && arg <= finallyEntry.finallyLoc && (finallyEntry = null); var record = finallyEntry ? finallyEntry.completion : {}; return record.type = type, record.arg = arg, finallyEntry ? (this.method = \"next\", this.next = finallyEntry.finallyLoc, ContinueSentinel) : this.complete(record); }, complete: function complete(record, afterLoc) { if (\"throw\" === record.type) throw record.arg; return \"break\" === record.type || \"continue\" === record.type ? this.next = record.arg : \"return\" === record.type ? (this.rval = this.arg = record.arg, this.method = \"return\", this.next = \"end\") : \"normal\" === record.type && afterLoc && (this.next = afterLoc), ContinueSentinel; }, finish: function finish(finallyLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.finallyLoc === finallyLoc) return this.complete(entry.completion, entry.afterLoc), resetTryEntry(entry), ContinueSentinel; } }, catch: function _catch(tryLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc === tryLoc) { var record = entry.completion; if (\"throw\" === record.type) { var thrown = record.arg; resetTryEntry(entry); } return thrown; } } throw new Error(\"illegal catch attempt\"); }, delegateYield: function delegateYield(iterable, resultName, nextLoc) { return this.delegate = { iterator: values(iterable), resultName: resultName, nextLoc: nextLoc }, \"next\" === this.method && (this.arg = undefined), ContinueSentinel; } }, exports; }\n\nfunction _createForOfIteratorHelper(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (!it) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; var F = function F() {}; return { s: F, n: function n() { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function e(_e) { throw _e; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var normalCompletion = true, didErr = false, err; return { s: function s() { it = it.call(o); }, n: function n() { var step = it.next(); normalCompletion = step.done; return step; }, e: function e(_e2) { didErr = true; err = _e2; }, f: function f() { try { if (!normalCompletion && it.return != null) it.return(); } finally { if (didErr) throw err; } } }; }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Interfaces and methods for training models using TensorFlow.js datasets.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { scalar } from '@tensorflow/tfjs-core';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { singletonOrArray, toList } from '../utils/generic_utils';\nimport { standardizeClassWeights, standardizeWeights } from './training_utils'; // Default batch size used during tensor-based validation.\n\nvar DEFAULT_VALIDATION_BATCH_SIZE = 32;\n/**\n * Standardize the output of a dataset iterator for use by\n * LayersModel.fitDataset().\n *\n * @param model: A `tf.LayersModel` object.\n * @param iteratorOut The output of a dataset iterator. It is required to be\n *   an object of the form `{xs: TensorOrArrayOrMap, ys:\n * TensorOrArrayOrMap}`, where `TensorOrArrayOrMap` is a single `tf.Tensor`,\n * a `tf.Tensor[]`, or a flat map from string names to `tf.Tensor`s.\n * @returns A flat array of `tf.Tensor` objects: the input `tf.Tensor`s\n *   followed by the target `tf.Tensor`s.  When `tf.Tensor`s are provided\n *   as a map, the order in the resulting array is taken from the `inputNames`\n *   and `outputNames` of the model.\n */\n\nfunction standardizeDataIteratorOutput( // Type `model` as `any` here to avoid circular dependency w/\n// training.ts.\n// tslint:disable-next-line:no-any\nmodel, iteratorOut) {\n  var xs;\n  var ys;\n  var iteratorOutObj = iteratorOut;\n  xs = iteratorOutObj['xs'];\n  ys = iteratorOutObj['ys'];\n  tfc.util.assert(xs != null && ys != null, function () {\n    return 'A Dataset iterator for fitDataset() is expected to generate ' + 'objects of the form `{xs: xVal, ys: yVal}`, where the two ' + 'values may be `tf.Tensor`, an array of Tensors, or a map of ' + 'string to Tensor.  The provided Dataset instead generates ' + \"\".concat(iteratorOut);\n  });\n  var flattenedXs = flattenTensorOrArrayOrMap('input', model.inputNames, xs);\n  var flattenedYs = flattenTensorOrArrayOrMap('output', model.outputNames, ys);\n  var batchSize = flattenedXs[0].shape[0];\n  tfc.util.assert(flattenedXs.length === model.inputs.length, function () {\n    return \"LayersModel has \".concat(model.inputs.length, \" inputs, but the dataset \") + \"provides \".concat(flattenedXs.length, \" inputs.  (Expected input keys: \") + \"\".concat(JSON.stringify(model.inputNames), \")\");\n  });\n  tfc.util.assert(flattenedYs.length === model.outputs.length, function () {\n    return \"LayersModel has \".concat(model.outputs.length, \" outputs, but the dataset \") + \"provides \".concat(flattenedYs.length, \" outputs.  (Expected output keys: \") + \"\".concat(JSON.stringify(model.outputNames), \")\");\n  });\n\n  var _loop = function _loop(xIndex) {\n    tfc.util.assert(flattenedXs[xIndex].shape[0] === batchSize, function () {\n      return \"Batch size mismatch: input \" + \"\".concat(model.inputNames[xIndex], \" has \").concat(flattenedXs[xIndex].shape[0], \"; \") + \"expected  \".concat(batchSize, \" based on input \").concat(model.inputNames[0], \".\");\n    });\n  };\n\n  for (var xIndex = 0; xIndex < flattenedXs.length; xIndex++) {\n    _loop(xIndex);\n  }\n\n  var _loop2 = function _loop2(yIndex) {\n    tfc.util.assert(flattenedYs[yIndex].shape[0] === batchSize, function () {\n      return \"Batch size mismatch: output \" + \"\".concat(model.outputNames[yIndex], \" has \").concat(flattenedYs[yIndex].shape[0], \"; \") + \"expected  \".concat(batchSize, \" based on input \").concat(model.inputNames[0], \".\");\n    });\n  };\n\n  for (var yIndex = 0; yIndex < flattenedYs.length; yIndex++) {\n    _loop2(yIndex);\n  }\n\n  return {\n    xs: flattenedXs,\n    ys: flattenedYs\n  };\n}\n\nfunction flattenTensorOrArrayOrMap(inputOrOutput, names, values) {\n  if (values instanceof tfc.Tensor) {\n    return [values];\n  } else if (Array.isArray(values)) {\n    tfc.util.assert(values.length === names.length, function () {\n      return \"Received an array of \".concat(values.length, \" Tensors, but expected \").concat(names.length, \" to match the \").concat(inputOrOutput, \" keys \").concat(names, \".\");\n    });\n    return values;\n  } else {\n    var result = []; // Check that all the required keys are available.\n\n    var _iterator = _createForOfIteratorHelper(names),\n        _step;\n\n    try {\n      for (_iterator.s(); !(_step = _iterator.n()).done;) {\n        var name = _step.value;\n\n        if (values[name] == null) {\n          throw new ValueError(\"The feature data generated by the dataset lacks the required \" + \"\".concat(inputOrOutput, \" key '\").concat(name, \"'.\"));\n        }\n\n        result.push(values[name]);\n      }\n    } catch (err) {\n      _iterator.e(err);\n    } finally {\n      _iterator.f();\n    }\n\n    return result;\n  }\n}\n\nfunction standardizeTensorValidationData(data) {\n  if (data.length === 3) {\n    throw new NotImplementedError('Validation with sample weights is not implemented yet.');\n  }\n\n  return {\n    xs: data[0],\n    ys: data[1]\n  };\n}\n\nexport function fitDataset(_x, _x2, _x3) {\n  return _fitDataset.apply(this, arguments);\n}\n/** Helper function that determines number of steps (batches) per epoch. */\n\nfunction _fitDataset() {\n  _fitDataset = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee( // Type `model` as `any` here to avoid circular dependency w/\n  // training.ts.\n  // tslint:disable-next-line:no-any\n  model, dataset, args) {\n    var hasBatchesPerEpoch, doValidation, valXs, valYs, validationData, trainFunction, outLabels, callbackMetrics, callbacks, verbose, _configureCallbacks, callbackList, history, epoch, dataIterator, epochLogs, stepsDone, batchIndex, iteratorOut, _standardizeDataItera, xs, ys, batchLogs, sampleWeights, standardClassWeights, i, ins, outs, _i, label, out, valOuts, _i2;\n\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            hasBatchesPerEpoch = args.batchesPerEpoch != null;\n            tfc.util.assert(model.optimizer != null, function () {\n              return 'You must compile a model before training/testing. Use ' + 'LayersModel.compile(modelCompileConfig).';\n            });\n            tfc.util.assert(args != null, function () {\n              return \"For fitDataset(), the 2nd argument (config) is required, \" + \"but it is not provided in this call.\";\n            });\n            tfc.util.assert(args.epochs != null && args.epochs > 0 && Number.isInteger(args.epochs), function () {\n              return \"For fitDataset(), config.epochs is expected to be a positive \" + \"integer, but got \".concat(args.epochs);\n            });\n            tfc.util.assert(!hasBatchesPerEpoch || args.batchesPerEpoch > 0 && Number.isInteger(args.batchesPerEpoch), function () {\n              return \"For fitDataset(), config.batchesPerEpoch is expected to be a \" + \"positive integer if specified, but got \".concat(args.batchesPerEpoch);\n            });\n            tfc.util.assert( // tslint:disable-next-line:no-any\n            args['validationSplit'] == null, function () {\n              return '`validationSplit` is not supported by `fitDataset()`. ' + 'Use validationData instead.';\n            });\n\n            if (!model.isTraining) {\n              _context.next = 8;\n              break;\n            }\n\n            throw new Error('Cannot start training because another fit() call is ongoing.');\n\n          case 8:\n            model.isTraining = true;\n            _context.prev = 9;\n            doValidation = args.validationData != null;\n\n            if (doValidation) {\n              if (isDatasetObject(args.validationData)) {\n                tfc.util.assert(args.validationBatches == null || args.validationBatches > 0 && Number.isInteger(args.validationBatches), function () {\n                  return \"For fitDataset() with dataset-based validation, \" + \"config.validationBatches is expected not to be provided, \" + \"or to be a positive integer, \" + \"but got \".concat(args.validationBatches);\n                });\n              } else {\n                validationData = standardizeTensorValidationData(args.validationData);\n                valXs = validationData.xs;\n                valYs = validationData.ys;\n              }\n            }\n\n            trainFunction = model.makeTrainFunction();\n            outLabels = model.getDedupedMetricsNames();\n\n            if (doValidation) {\n              callbackMetrics = outLabels.slice().concat(outLabels.map(function (n) {\n                return 'val_' + n;\n              }));\n            } else {\n              callbackMetrics = outLabels.slice();\n            }\n\n            callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n            verbose = args.verbose == null ? 1 : args.verbose;\n            _configureCallbacks = configureCallbacks(callbacks, verbose, args.epochs, null, null, getStepsPerEpoch(dataset, args), null, // Batch size determined by the dataset itself.\n            doValidation, callbackMetrics), callbackList = _configureCallbacks.callbackList, history = _configureCallbacks.history;\n            callbackList.setModel(model);\n            model.history = history;\n            _context.next = 22;\n            return callbackList.onTrainBegin();\n\n          case 22:\n            model.stopTraining_ = false;\n            epoch = args.initialEpoch == null ? 0 : args.initialEpoch;\n            _context.next = 26;\n            return dataset.iterator();\n\n          case 26:\n            dataIterator = _context.sent;\n\n          case 27:\n            if (!(epoch < args.epochs)) {\n              _context.next = 98;\n              break;\n            }\n\n            epochLogs = {};\n            _context.next = 31;\n            return callbackList.onEpochBegin(epoch);\n\n          case 31:\n            stepsDone = 0;\n            batchIndex = 0;\n\n            if (hasBatchesPerEpoch) {\n              _context.next = 37;\n              break;\n            }\n\n            _context.next = 36;\n            return dataset.iterator();\n\n          case 36:\n            dataIterator = _context.sent;\n\n          case 37:\n            if (!(hasBatchesPerEpoch ? stepsDone < args.batchesPerEpoch : true)) {\n              _context.next = 91;\n              break;\n            }\n\n            _context.next = 40;\n            return dataIterator.next();\n\n          case 40:\n            iteratorOut = _context.sent;\n\n            if (!(hasBatchesPerEpoch && iteratorOut.done)) {\n              _context.next = 44;\n              break;\n            }\n\n            console.warn('You provided `batchesPerEpoch` as ' + \"\".concat(args.batchesPerEpoch, \", \") + 'but your dataset iterator ran out of data after ' + \"\".concat(stepsDone, \" batches; \") + 'interrupting training. Make sure that your ' + 'dataset can generate at least `batchesPerEpoch * epochs` ' + 'batches (in this case, ' + \"\".concat(args.batchesPerEpoch * args.epochs, \" batches). \") + 'You may need to use the repeat() function when building ' + 'your dataset.');\n            return _context.abrupt(\"break\", 91);\n\n          case 44:\n            if (!(iteratorOut.value != null)) {\n              _context.next = 73;\n              break;\n            }\n\n            _standardizeDataItera = standardizeDataIteratorOutput(model, iteratorOut.value), xs = _standardizeDataItera.xs, ys = _standardizeDataItera.ys;\n            batchLogs = {};\n            batchLogs['batch'] = batchIndex;\n            batchLogs['size'] = xs[0].shape[0];\n            _context.next = 51;\n            return callbackList.onBatchBegin(batchIndex, batchLogs);\n\n          case 51:\n            sampleWeights = [];\n\n            if (!(args.classWeight != null)) {\n              _context.next = 64;\n              break;\n            }\n\n            standardClassWeights = standardizeClassWeights(args.classWeight, model.outputNames);\n            i = 0;\n\n          case 55:\n            if (!(i < standardClassWeights.length)) {\n              _context.next = 64;\n              break;\n            }\n\n            _context.t0 = sampleWeights;\n            _context.next = 59;\n            return standardizeWeights(ys[i], null, standardClassWeights[i]);\n\n          case 59:\n            _context.t1 = _context.sent;\n\n            _context.t0.push.call(_context.t0, _context.t1);\n\n          case 61:\n            ++i;\n            _context.next = 55;\n            break;\n\n          case 64:\n            // Train on batch.\n            ins = xs.concat(ys).concat(sampleWeights);\n            outs = trainFunction(ins);\n            tfc.dispose(ins);\n\n            for (_i = 0; _i < outLabels.length; ++_i) {\n              label = outLabels[_i];\n              out = outs[_i];\n              batchLogs[label] = out;\n              tfc.keep(out);\n            }\n\n            _context.next = 70;\n            return callbackList.onBatchEnd(batchIndex, batchLogs);\n\n          case 70:\n            disposeTensorsInLogs(batchLogs);\n            batchIndex++;\n            stepsDone++;\n\n          case 73:\n            if (!(hasBatchesPerEpoch ? stepsDone >= args.batchesPerEpoch : iteratorOut.done)) {\n              _context.next = 87;\n              break;\n            }\n\n            if (!doValidation) {\n              _context.next = 86;\n              break;\n            }\n\n            valOuts = void 0;\n\n            if (!isDatasetObject(args.validationData)) {\n              _context.next = 84;\n              break;\n            }\n\n            _context.t2 = toList;\n            _context.next = 80;\n            return model.evaluateDataset(args.validationData, {\n              batches: args.validationBatches\n            });\n\n          case 80:\n            _context.t3 = _context.sent;\n            valOuts = (0, _context.t2)(_context.t3);\n            _context.next = 85;\n            break;\n\n          case 84:\n            valOuts = toList(model.evaluate(valXs, valYs, {\n              batchSize: args.validationBatchSize == null ? DEFAULT_VALIDATION_BATCH_SIZE : args.validationBatchSize,\n              verbose: 0\n            }));\n\n          case 85:\n            for (_i2 = 0; _i2 < model.metricsNames.length; ++_i2) {\n              epochLogs[\"val_\".concat(model.metricsNames[_i2])] = valOuts[_i2];\n            }\n\n          case 86:\n            return _context.abrupt(\"break\", 91);\n\n          case 87:\n            if (!model.stopTraining_) {\n              _context.next = 89;\n              break;\n            }\n\n            return _context.abrupt(\"break\", 91);\n\n          case 89:\n            _context.next = 37;\n            break;\n\n          case 91:\n            _context.next = 93;\n            return callbackList.onEpochEnd(epoch, epochLogs);\n\n          case 93:\n            epoch++;\n\n            if (!model.stopTraining_) {\n              _context.next = 96;\n              break;\n            }\n\n            return _context.abrupt(\"break\", 98);\n\n          case 96:\n            _context.next = 27;\n            break;\n\n          case 98:\n            _context.next = 100;\n            return callbackList.onTrainEnd();\n\n          case 100:\n            _context.next = 102;\n            return model.history.syncData();\n\n          case 102:\n            return _context.abrupt(\"return\", model.history);\n\n          case 103:\n            _context.prev = 103;\n            model.isTraining = false;\n            return _context.finish(103);\n\n          case 106:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee, null, [[9,, 103, 106]]);\n  }));\n  return _fitDataset.apply(this, arguments);\n}\n\nfunction getStepsPerEpoch(dataset, args) {\n  // Attempt to determine # of batches in an epoch.\n  var stepsPerEpoch = null;\n\n  if (args.batchesPerEpoch != null) {\n    stepsPerEpoch = args.batchesPerEpoch;\n  } else if (Number.isFinite(dataset.size)) {\n    stepsPerEpoch = dataset.size;\n  }\n\n  return stepsPerEpoch;\n} // Check if provided object is a Dataset object by checking its .iterator\n// element.\n\n\nfunction isDatasetObject(dataset) {\n  return typeof dataset.iterator === 'function';\n} // Check if provided object is a LazyIterator object by checking it's .next\n// element.\n\n\nfunction isLazyIteratorObject(iterator) {\n  return typeof iterator.next === 'function';\n}\n\nexport function evaluateDataset(_x4, _x5, _x6) {\n  return _evaluateDataset.apply(this, arguments);\n}\n\nfunction _evaluateDataset() {\n  _evaluateDataset = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2( // Type `model` as `any` here to avoid circular dependency w/\n  // training.ts.\n  // tslint:disable-next-line:no-any\n  model, dataset, args) {\n    var hasBatches, f, outs, dataIterator, numExamples, batch, _loop3, _ret, i, oldScalar;\n\n    return _regeneratorRuntime().wrap(function _callee2$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            args = args || {};\n            hasBatches = args.batches != null;\n            f = model.testFunction;\n            outs = [];\n\n            if (!(args.verbose > 0)) {\n              _context3.next = 6;\n              break;\n            }\n\n            throw new NotImplementedError('Verbose mode is not implemented yet.');\n\n          case 6:\n            tfc.util.assert(!hasBatches || args.batches > 0 && Number.isInteger(args.batches), function () {\n              return 'Test loop expects `batches` to be a positive integer, but ' + \"received \".concat(JSON.stringify(args.batches));\n            });\n\n            if (!isLazyIteratorObject(dataset)) {\n              _context3.next = 11;\n              break;\n            }\n\n            _context3.t0 = dataset;\n            _context3.next = 14;\n            break;\n\n          case 11:\n            _context3.next = 13;\n            return dataset.iterator();\n\n          case 13:\n            _context3.t0 = _context3.sent;\n\n          case 14:\n            dataIterator = _context3.t0;\n            // Keeps track of number of examples used in this evaluation.\n            numExamples = 0;\n            batch = 0;\n            _loop3 = /*#__PURE__*/_regeneratorRuntime().mark(function _loop3() {\n              var iteratorOut;\n              return _regeneratorRuntime().wrap(function _loop3$(_context2) {\n                while (1) {\n                  switch (_context2.prev = _context2.next) {\n                    case 0:\n                      _context2.next = 2;\n                      return dataIterator.next();\n\n                    case 2:\n                      iteratorOut = _context2.sent;\n                      outs = tfc.tidy(function () {\n                        if (iteratorOut.value) {\n                          (function () {\n                            // TODO(cais): Once real dataset is available, use\n                            //   `map(x => standardizeDataIteratorOutput(model, x).map(f)`.\n                            var _standardizeDataItera2 = standardizeDataIteratorOutput(model, iteratorOut.value),\n                                xs = _standardizeDataItera2.xs,\n                                ys = _standardizeDataItera2.ys;\n\n                            var xsAndYs = xs.concat(ys);\n                            var batchOuts = tfc.tidy(function () {\n                              return f(xsAndYs);\n                            });\n                            tfc.dispose(xsAndYs);\n\n                            if (batch === 0) {\n                              for (var _i3 = 0; _i3 < batchOuts.length; ++_i3) {\n                                outs.push(scalar(0));\n                              }\n                            }\n\n                            var batchSize = xsAndYs[0].shape[0];\n\n                            var _loop4 = function _loop4(_i4) {\n                              var batchOut = batchOuts[_i4];\n                              var oldScalar = outs[_i4];\n                              outs[_i4] = tfc.tidy(function () {\n                                return tfc.add(outs[_i4], tfc.mul(batchSize, batchOut));\n                              });\n\n                              if (batch > 0) {\n                                tfc.dispose(oldScalar);\n                              }\n                            };\n\n                            for (var _i4 = 0; _i4 < batchOuts.length; ++_i4) {\n                              _loop4(_i4);\n                            }\n\n                            tfc.dispose(batchOuts);\n                            numExamples += batchSize;\n                            ++batch;\n                          })();\n                        }\n\n                        return outs;\n                      });\n\n                      if (!iteratorOut.done) {\n                        _context2.next = 7;\n                        break;\n                      }\n\n                      if (hasBatches) {\n                        console.warn('Your dataset iterator ran out of data during evaluateDataset(). ' + 'Interrupting evalution. Make sure that your ' + 'dataset can generate at least `batches` ' + \"batches (in this case, \".concat(args.batches, \" batches). \") + 'You may need to use the repeat() function when building ' + 'your dataset.');\n                      }\n\n                      return _context2.abrupt(\"return\", \"break\");\n\n                    case 7:\n                    case \"end\":\n                      return _context2.stop();\n                  }\n                }\n              }, _loop3);\n            });\n\n          case 18:\n            if (!(hasBatches ? batch < args.batches : true)) {\n              _context3.next = 25;\n              break;\n            }\n\n            return _context3.delegateYield(_loop3(), \"t1\", 20);\n\n          case 20:\n            _ret = _context3.t1;\n\n            if (!(_ret === \"break\")) {\n              _context3.next = 23;\n              break;\n            }\n\n            return _context3.abrupt(\"break\", 25);\n\n          case 23:\n            _context3.next = 18;\n            break;\n\n          case 25:\n            for (i = 0; i < outs.length; ++i) {\n              oldScalar = outs[i];\n              outs[i] = tfc.div(outs[i], numExamples);\n              tfc.dispose(oldScalar);\n            }\n\n            return _context3.abrupt(\"return\", singletonOrArray(outs));\n\n          case 27:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee2);\n  }));\n  return _evaluateDataset.apply(this, arguments);\n}","map":null,"metadata":{},"sourceType":"module"}