{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, FusedConv2D, util } from '@tensorflow/tfjs-core';\nimport { Conv2DProgram } from '../conv_gpu';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { conv2dByMatMul, conv2dWithIm2Row } from './Conv2D_impl';\nimport { reshape } from './Reshape';\nexport function fusedConv2d(args) {\n  var inputs = args.inputs,\n      backend = args.backend,\n      attrs = args.attrs;\n  var x = inputs.x,\n      filter = inputs.filter,\n      bias = inputs.bias,\n      preluActivationWeights = inputs.preluActivationWeights;\n  var strides = attrs.strides,\n      pad = attrs.pad,\n      dataFormat = attrs.dataFormat,\n      dilations = attrs.dilations,\n      dimRoundingMode = attrs.dimRoundingMode,\n      activation = attrs.activation,\n      leakyreluAlpha = attrs.leakyreluAlpha;\n  var $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  var convInfo = backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false\n  /* depthwise */\n  , $dataFormat);\n  var out;\n  var intermediates = [];\n\n  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === 'SAME' || convInfo.padInfo.type === 'VALID')) {\n    out = conv2dByMatMul({\n      x: x,\n      filter: filter,\n      convInfo: convInfo,\n      backend: backend,\n      bias: bias,\n      activation: activation,\n      preluActivationWeights: preluActivationWeights,\n      leakyreluAlpha: leakyreluAlpha\n    });\n  } else if (env().getBool('WEBGL_CONV_IM2COL') && x.shape[0] === 1) {\n    out = conv2dWithIm2Row({\n      x: x,\n      filter: filter,\n      convInfo: convInfo,\n      backend: backend,\n      bias: bias,\n      activation: activation,\n      preluActivationWeights: preluActivationWeights,\n      leakyreluAlpha: leakyreluAlpha\n    });\n  } else {\n    var hasBias = bias != null;\n    var hasPreluActivationWeights = preluActivationWeights != null;\n    var hasLeakyreluAlpha = activation === 'leakyrelu';\n    var fusedActivation = activation ? mapActivationToShaderProgram(activation, false) : null;\n    var program = new Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n    var _inputs = [x, filter];\n\n    if (bias) {\n      _inputs.push(bias);\n    }\n\n    if (preluActivationWeights) {\n      _inputs.push(preluActivationWeights);\n    }\n\n    if (hasLeakyreluAlpha) {\n      var $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n\n      _inputs.push($leakyreluAlpha);\n\n      intermediates.push($leakyreluAlpha);\n    }\n\n    out = backend.runWebGLProgram(program, _inputs, 'float32');\n  }\n\n  var outReshaped = reshape({\n    inputs: {\n      x: out\n    },\n    backend: backend,\n    attrs: {\n      shape: convInfo.outShape\n    }\n  });\n  intermediates.push(out);\n  intermediates.forEach(function (t) {\n    return backend.disposeIntermediateTensorInfo(t);\n  });\n  return outReshaped;\n}\nexport var fusedConv2DConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'webgl',\n  kernelFunc: fusedConv2d\n};","map":null,"metadata":{},"sourceType":"module"}